# Аналитика погодных условий во всех столицах мира

## О проекте

Проект выполняет автоматический сбор и анализ погодных данных для всех столиц мира за последнюю неделю.  

Используя API **_Open-Meteo_**, данные обрабатываются в `pandas`, анализируются и визуализируются с помощью `matplotlib`.
Вся работа завернута в CLI-интерфейс, позволяющий быстро получать таблицы, строить графики и сохранять результаты.

---
## Инструменты

| Компонент        | Назначение                                         |
| ---------------- |----------------------------------------------------|
| **Python**       | Основной язык разработки                           |
| **requests**     | Получение данных из Open-Meteo API                 |
| **pandas**       | Очистка, анализ и агрегация данных                 |
| **matplotlib**   | Визуализация результатов                           |
| **scikit-learn** | Оценка влияния факторов на определенный показатель |


## Задачи и реализация

### 1. Подготовка данных о столицах

- [x] Сгенерировать csv файл с следующими данными:

| Country | Capital | Latitude | Longitude | Timezone     |
|---------|---------|----------|-----------|--------------|
| France  | Paris   | 48.8566  | 2.3522    | Europe/Paris |
| ...     | ...     | ...      | ...       | ...          |

- **Итог:** 195 строк
- **Файл:** `data/capitals.csv`
- **PS:** Реализовано с помощью **Claude**
---
### 2. Сбор данных с [Open-Meteo API](https://open-meteo.com/)
Нужно для каждой столицы получить почасовые данные за последние 7 дней:
- [x] _температура **( temperature_2m )**_
- [x] _скорость ветра **( wind_speed_10m )**_
- [x] _влажность **( relative_humidity_2m )**_
- [x] _как ощущается температура **( apparent_temperature )**_
- [x] _осадки **( precipitation )**_


- **Реализовано в** `./get_meteo_data.py`
- **Файл:** `data/meteo_data.json`
---
### 3. Очистка и форматирование данных

- [x] Проверить пропуски (`NaN`) и при необходимости заполнить или удалить
- [x] Привести колонки к удобному формату


- **Реализовано в** `./data_processing.py`
---
### 4. Анализ данных

Для каждого города рассчитать:
- [x] среднюю дневную температуру
- [x] дневной максимум и минимум
- [x] амплитуду ( max-min )

|city|min_temp|max_temp|avg_temp|amplitude|
|----|--------|-------|--------|---------|
|Abu Dhabi|28.8  |32.2    |30.74|3.4|

- [x] Найти город с наибольшей колебательностью температуры

|city|Astana|
|----|------|
|amplitude|25.0|

- **Реализовано в** `./data_processing.py`
- Команда для вызова `python main.py --tables`
---
### 5. Визуализация

> Все графики можно вызывать через CLI. (примеры далее).

- [x] График (bar) амплитуды температуры по городам c аннотацией для каждого столбца


- [x] Линейный, почасовой график температуры за неделю для конкретного города


- [x] График (bar), который показывает, как влияют влажность, скорость ветра и осадки на показатель ощущения температуры (apparent_temperature)

#### Доступные команды:
| График                    | Описание                                                                     | Пример вызова                          |
| ------------------------- | ---------------------------------------------------------------------------- | -------------------------------------- |
| Амплитуда температуры     | Столбчатая диаграмма по всем городам                                         | `python main.py --amplitude`           |
| Почасовая температура     | Линейный график за неделю для города                                         | `python main.py --weekly --city Paris` |
| Влияние погодных факторов | Столбчатая диаграмма зависимости ощущения температуры от ветра, влажности и осадков | `python main.py --influence`           |

---
### 6. CLI-интерфейс

В конце каждой команды, описанной в пункте **5**, можно добавить флаг `--save`, что бы сохранить вызываемый график как png

- Пример для сохранения графика: `python main.py --amplitude --save`

## Дополнительные возможности

- Полученный чрез API `.json` файл обработан в скрипте `./build_database.py`. Результат — две связанные таблицы `cities` и `weather` в **SQLite**.
- Для практики реализована тестовая функция **CRUD**, создающая агрегированную копию таблицы из анализа (п.4)

## Установка и запуск

### 1. Склонировать репозиторий:
```bash
git clone https://github.com/<username>/weather-analytics.git
cd weather_analytics
```
### 2. Создать виртуальное окружение и активировать его:
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate
```
### 3. Установить зависимости:
```bash
pip install -r requirements.txt
```
### 4. Запуск проекта:
- Вывод таблиц:
```bash
python main.py --tables
```
- Строительство графиков:
```bash
python main.py --amplitude
python main.py --weekly --city Paris
python main.py --influence
```
- Сохранение графиков:
```bash
python main.py --amplitude --save
```
---
## Примечания

- Использование `scikit-learn` на текущем этапе было реализовано с помощью AI.
- Я сохранил все промежуточные файлы, которые были получены в процессе разработки для визуального ознакомления и возможного тестирования проекта
